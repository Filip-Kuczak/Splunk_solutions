In this document my solutions for the tasks from SOC.docx will be presented.

--- General assumptions ---

For this assignment, I assumed that there are three servers running Ubuntu 22.04.2 LTS. One of these servers is Splunk server, that is setup according to the requirements from tasks, second server is a fresh minimal
headless installation of Ubuntu 22.04.2 LTS (no splunk, no Linux prerequisites, just pure system), finally the third server will be external ansible server (also running Ubuntu) with ansible installed and synced with 
Splunk_solutions repository. In this document will be described:

- automatic deployment of Splunk instance with all prerequisites
- configuring splunk server(all in one deployment) according to the requirements from Tasks 1 & 2
- automation of Splunk configuration management, as well as the necessary components of the operating system.


1. Splunk deployment Automation

a. Ansible user configuration(simone)

First of all, the SSH key for ansible needs to be created. It can be done by issuing this command on ansible server:

ssh-keygen -t ed25519 -C "ansible"

Then public key need to be added on server(s) that we want to manage with ansible:

ssh-copy-id -i ~/.ssh/ansible.pub <server(s)_ip>

Next important step is to create ansible user on remote server(s). Ansible can be used to do that with the playbook ansible_setup.yml from Splunk_solutions repo. This is the only ansible command that will need sudo password
from a remote server user. This command will create simone user for managing ansible on remote server:

ansible-playbook ansible_setup.yml --ask-become-pass

b. Installing splunk and Linux prerequisites on remote server(s). To install Splunk and Linux prerequisites install.yml playbook will be used. This is a slightly modified version of the playbook created and shared on https://github.com/johnmcgovern/ansible-splunk-base . Unfortunately Splunk version 8.2.9 on Ubuntu 22.04.2 has problem related with Linux cgroups (https://community.splunk.com/t5/Installation/Why-is-Systemd-broken-on-new-install/td-p/482881), to fix that I changed line 215 in core-installation playbook. To install splunk with all Linux prerequisites issue that command on ansible server:

ansible-playbook install.yml -u simone         (optionally line 14 in /Splunk_solutions/group_vars/all could be uncommented, after that -u flag will not be needed in 
further executions)

after that, splunk_version: 8.2.9 will be installed and user splunk will be created. Splunk will be managed by systemd

2. Tasks:

General approach(proposed as a solution) on how to maintain and control splunk configuration, is to use apps that will store particular parts of configuration. For the sake of these tasks I decided to create a separate app to reflect each aspect mentioned in SOC.docx objectives. Code for apps is stored in Splunk_solutions/roles/splunk_all_in_one/files/apps

a. TCP/UDP inputs - to represent this, Quadcode_syslog_inputs app was created. Inside there are simple tcp input in inputs.conf and index syslog_data created (in indexes.conf). Data source is set to default splunk syslog.

b. (TASK 2)For REST API inputs, Quadcode_blocklist_monitor app was created. Splunk will run blocklist.py script every 3600 (1 hour) . For this input, custom sourcetype was created (blocklist). As collected data consists only of ip addresses I created really simple props.conf to create line breaking and transforms.conf to demonstrate potential regex usage. In props.conf basic eval was used to show calculated fields creation. Below is the screenshot of indexed data from scripted input:

![Script execution](https://github.com/Filip-Kuczak/Splunk_solutions/assets/77390537/77140973-bb64-49cb-a4ff-2f4125f6216c)

![blocklist_monitor 2 ](https://github.com/Filip-Kuczak/Splunk_solutions/assets/77390537/7bd69b5f-897b-4dab-8923-6f8618e33917)

splunkd log screenshot (scripted input evidence):

![Script execution](https://github.com/Filip-Kuczak/Splunk_solutions/assets/77390537/fdfff6b1-f7f3-411c-a47b-3ab821e972d0)


As for the script itself it is really simple python code that checks current time and subtracts 3600 from it. Then epoch value of current time - 3600 seconds is provided as argument for time= parameter in blocklit api. 

c. Quadcode_monitoring app contains simple schedule search (in savedsearches.conf) that queries blocklist index for any occurrences of IPv6. It is scheduled to run every 45th minute.

d. Quadcode_local_inputs queries local file error.log generated by apache2 (of course there is a great TA for Apache which I reccomend for professional usage:) ) for the sake of local logs ingestion. According to the task description from SOC.docx, the previous engineer did not leave decent documentation but we know the names of the services and we can check what files are monitored (for exapmle by running btool over inputs.conf ) . These two facts connected together should give us a clear picture on what services should be started on a potential replicated server. 

3. App management and server migration strategy. 

When splunk configurations are managed via apps there is a big possibility to be very flexible with replicating configurations. Strategy to maintain and store configs is as follows:


a. Apps are stored in git within ansible splunk_all_in_one role 
b. Naming convention is that names always start with Quadcode_
c. Configs are modified within ansible role and then deployed with ansible playbook splunk_all_in_one.yml
d. Users keep config in sync with git repo. 
e. If for some reasons any changes needs to be done within $SPLUNK_HOME/etc/system/local then it should be stored in system_local directory within ansible role and managed via ansible
f. General configs like splunk users and roles(authorize.conf , authentication.conf) should also be kept in separate apps/app, this will help with server restoration/migration.              
APP MANAGEMENT

The system for managing apps is really simple. Ansible will copy all apps that from splunk_all_in_one role /files/apps and /files/system_local to $SPLUNK_HOME/etc/apps and $SPLUNK_HOME/etc/system/local, by that the old version will be replaced by most recent version from git and splunk config will be always in sync with git. Ansible role will also take care of assigning poprer user, group and files/directories permissions. The potential disadvantage of this solution is the fact that we don't have control over deleted apps. For example if an app is deleted from git/ansible, then the last version will remain on splunk server. The solution might be to delete it manually or add an additional step to ansible role which will delete all apps starting from Quadcode_ and then put the newest versions (it won't be dangerous because splunk will start using new configurations only after restart). The second solution is less efficient, that's why it should be discussed before potential implementation.

MIGRATION 

First of all, make sure that all applications are managed by GIT, up to date, managed by ansible and follow the naming conventions(also potential system/local files should be checked). If not, it should be corrected before proceeding to the next steps. In the case of Splunk_solutions repo everything is set well and up to date. Next step will be to make sure that all systemd services are added to splunk_all_in_one role. In ansible splunk_all_in_one role:  there is always check if server repositories are up to date (if not ansible will update it), and if important services are running, if not ansible will update them (in case of this task it is just apache2 but there is potential for more services).   


As in the task 1 from SOC.docx it was mentioned that splunk ingests data via TCP/UDP then using DNS name instead of just ip address would be a good solution and will prevent from any potential configuration changes that would have to be done on devices sending data to Splunk. It will also prevent any downtime during migration because the migrated server will be able to be fully checked before making changes in DNS records. 

Another network related issue worth considering is connectivity between devices sending logs and new splunk server (there might be need to create some rules on firewall). 

If data  sent via TCP/UDP is encrypted the SSL certs also should be copied.

If external storage is used, the connectivity between the new server and storage should be checked.


Using this method is relatively fast and safe to migrate splunk all_in_one server to another machine. After installing splunk and prerequisites Engineer should log in and check if splunk works as expected, then if all requirements mentioned above are met, the dnsnaeme/ip address of new server should be added in splunk server1 stanza in inventory file from Splunk_solutions repo. After checking if everything is working fine, dns name should be switched to the new server.

What is out of scope for this task( but essential to consider) is how to handle migration and management of heavy knowledge objects like lookups and/or dashboards. As this is not the subject for this particular exercise I skipped that aspect, but for real-life example, solution for that should be provided. The same for installing all the same TA's and apps from Splunk-base on new server. The process of deploying the same set of Splunk-base Apps/TAs on a new server should be automated as well. Last, but not least make sure that the server has access to a valid license. It can be achieved by copying splunk license from an old to the new server(via ansible or manually in the case when we create only one new server as in the case described in this document) or by connecting splunk server to license master( if it exists in the infrastructure).  Configuration for the second option can be stored in app and deployed with proposed app management  solution. 
